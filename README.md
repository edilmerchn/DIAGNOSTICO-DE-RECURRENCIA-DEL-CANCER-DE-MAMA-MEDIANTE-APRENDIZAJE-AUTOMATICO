# DIAGNOSTICO DE RECURRENCIA DEL CANCER DE MAMA MEDIANTE APRENDIZAJE AUTOM√ÅTICO

# Diagn√≥stico de Recurrencia del C√°ncer de Mama mediante Aprendizaje Autom√°tico

Este proyecto tiene como objetivo aplicar algoritmos de aprendizaje autom√°tico para predecir la recurrencia del c√°ncer de mama utilizando el conjunto de datos de Breast Cancer del repositorio UCI. Se eval√∫an tres modelos supervisados: Regresi√≥n Log√≠stica, √Årbol de Decisi√≥n y M√°quina de Vectores de Soporte (SVM) con n√∫cleo RBF.

## üìä Modelos Implementados

- Regresi√≥n Log√≠stica
- √Årbol de Decisi√≥n
- SVM con kernel RBF

## üìÅ Estructura del Proyecto

- `data/`: conjunto de datos preprocesado
- `notebooks/`: an√°lisis exploratorio, codificaci√≥n, entrenamiento y evaluaci√≥n de modelos
- `models/`: archivos serializados de los modelos entrenados (opcional)
- `results/`: matrices de confusi√≥n y m√©tricas

## ‚öôÔ∏è Requisitos

- Python 3.8+
- scikit-learn
- pandas
- matplotlib
- seaborn
- numpy

Instalar con:

```bash
pip install -r requirements.txt

## Descripci√≥n del Proyecto
## Conjunto de datos
</head>
<body>

<img src="img/1.png" width="400" align="right"/>

El conjunto de datos utilizado en este proyecto es el conjunto de datos de https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic, que consta de caracter√≠sticas calculadas a partir de una imagen digitalizada de una aspiraci√≥n con aguja fina (PAAF) de una masa mamaria. La variable objetivo indica si la masa es benigna (0) o maligna (1).

<br><br><br><br><br><br><br><br><br><br>

El cuaderno "DIAGNOSTICO_TEMPRANO_DEL_CANCER_DE_MAMA_MEDIANTE_APRENDIZAJE_AUTOMATICO", contiene el flujo completo de un proyecto de *machine learning* aplicado a datos m√©dicos, incluyendo:

- Importaci√≥n y exploraci√≥n del conjunto de datos de c√°ncer de mama desde el repositorio UCI.
- Limpieza y preprocesamiento de datos.
- Visualizaci√≥n exploratoria de las variables.
- Comparaci√≥n de m√∫ltiples algoritmos de clasificaci√≥n:
  - Regresi√≥n Log√≠stica
  - √Årboles de Decisi√≥n
  - XGBoost
- Evaluaci√≥n de modelos mediante m√©tricas como precisi√≥n, recall, f1-score y matriz de confusi√≥n.

Este flujo permite identificar el modelo m√°s eficiente para la tarea de clasificaci√≥n binaria entre tumores benignos y malignos.

## Tecnolog√≠as Utilizadas

- **Python 3**
- **Pandas**: manipulaci√≥n de datos
- **NumPy**: operaciones matem√°ticas
- **Matplotlib y Seaborn**: visualizaci√≥n
- **Scikit-learn**: modelado, m√©tricas, preprocesamiento
- **XGBoost**: modelo de boosting avanzado
- **ucimlrepo**: descarga del dataset desde la UCI Machine Learning Repository

## Estructura del Proyecto

```
diagnostico-cancer-mama/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ diagnostico_cancer_mama.ipynb     # Cuaderno principal del an√°lisis
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                      # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md                             # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ LICENSE                               # Licencia MIT
‚îî‚îÄ‚îÄ .gitignore                            # Archivos a ignorar por Git
```

## C√≥mo Empezar

1. **Clona el repositorio**
```bash
   git clone https://github.com/edilmerchn/DIAGNOSTICO_TEMPRANO_DEL_CANCER_DE_MAMA_MEDIANTE_APRENDIZAJE_AUTOMATICO
   cd DIAGNOSTICO_TEMPRANO_DEL_CANCER_DE_MAMA_MEDIANTE_APRENDIZAJE_AUTOMATICO
```

2. **Instala las dependencias**
```bash
pip install -r requirements.txt
```

3. **Ejecuta el notebook**
```bash
jupyter notebook notebooks/DIAGNOSTICO_TEMPRANO_DEL_CANCER_DE_MAMA_MEDIANTE_APRENDIZAJE_AUTOMATICO
.ipynb
```

## Evaluaci√≥n de Modelos

Se evaluaron diferentes clasificadores y se midi√≥ su desempe√±o con las siguientes m√©tricas:

- **Precisi√≥n (Accuracy)**
- **Sensibilidad (Recall)**
- **Puntaje F1**
- **Matriz de Confusi√≥n**

## Archivos:

   **breast_cancer_diagnosis.ipynb: cuaderno de diagn√≥stico**

    **requirements.txt: librer√≠as necesarias**

    **dataset/wdbc.data: muestra de dataset**

## Resultados del proyecto:
  1. Rendimiento de los modelos de aprendizaje autom√°tico
**REGRESI√ìN LOG√çSTICA** El modelo de regresi√≥n log√≠stica se desempe√±√≥ excelentemente con los datos preprocesados.  
Gracias a la eliminaci√≥n de variables poco informativas y colineales, y al escalado adecuado, el modelo logr√≥ un desempe√±o muy cercano al ideal, clasificando correctamente 168 de 171 casos.
Esto demuestra que, incluso modelos simples como la regresi√≥n log√≠stica, pueden alcanzar gran precisi√≥n cuando se aplican buenas pr√°cticas de an√°lisis exploratorio y preparaci√≥n de datos.

**Reporte de Clasificaci√≥n regresi√≥n log√≠stica**

| Clase | Precisi√≥n | Recall | F1-score | Soporte |
|-------|-----------|--------|----------|---------|
| **0 (Benigno)** | 0.97 | 1.00 | 0.99 | 107 |
| **1 (Maligno)** | 1.00 | 0.95 | 0.98 | 64 |

| M√©trica global | Precisi√≥n | Recall | F1-score | Soporte |
|----------------|-----------|--------|----------|---------|
| **Accuracy**        | 0.98 | ‚Äî | ‚Äî | 171 |
| **Macro promedio**  | 0.99 | 0.98 | 0.98 | 171 |
| **Ponderado promedio** | 0.98 | 0.98 | 0.98 | 171 |

**Matriz de confusi√≥n**
<img src="img/2.png" width="400" align="center"/>

**XGBOOST** El modelo XGBoost mostr√≥ un rendimiento muy alto, clasificando correctamente 165 de 171 muestras del conjunto de prueba.  
Aunque no alcanz√≥ la precisi√≥n absoluta del modelo de regresi√≥n log√≠stica en este caso, logr√≥ una excelente capacidad predictiva.
Es un modelo robusto que no requiere tanto preprocesamiento, lo que lo hace muy √∫til en proyectos reales, especialmente cuando hay relaciones complejas entre variables.
**Reporte de Clasificaci√≥n XGBOOST**

| Clase            | Precisi√≥n | Recall | F1-score | Soporte |
|------------------|-----------|--------|----------|---------|
| **0 (Benigno)**  | 0.96      | 0.98   | 0.97     | 107     |
| **1 (Maligno)**  | 0.97      | 0.94   | 0.95     | 64      |

| M√©trica global       | Precisi√≥n | Recall | F1-score | Soporte |
|----------------------|-----------|--------|----------|---------|
| **Accuracy**         | 0.96      | ‚Äî      | ‚Äî        | 171     |
| **Macro promedio**   | 0.97      | 0.96   | 0.96     | 171     |
| **Ponderado promedio** | 0.96    | 0.96   | 0.96     | 171     |

**Matriz de confusi√≥n**
<img src="img/3.png" width="500" align="center"/>

**√çNDICE ADICIONAL PARA COMPARAR: AUC-ROC**
- Ambos modelos se desempe√±aron excelentemente gracias al correcto preprocesamiento.
- La regresi√≥n log√≠stica super√≥ levemente a XGBoost en este caso espec√≠fico, probablemente por la linealidad y simplicidad de los datos.
- XGBoost sigue siendo un modelo potente, especialmente √∫til en datasets con relaciones no lineales o sin necesidad de escalar variables.
- El uso de √≠ndices adicionales como AUC y Kappa fue clave para hacer una comparaci√≥n m√°s justa y robusta entre los modelos.
Este an√°lisis demuestra que la preparaci√≥n de los datos tiene un gran impacto en el rendimiento final de cualquier modelo de machine learning.
**Matriz de confusi√≥n**
<img src="img/4.png" width="500" align="center"/>


## Conclusi√≥nes:

- Los modelos de **Regresi√≥n Log√≠stica** y **XGBoost** alcanzaron altos niveles de precisi√≥n (96‚ÄØ% y 97‚ÄØ% respectivamente), demostrando su efectividad en la detecci√≥n temprana del c√°ncer de mama.

- El preprocesamiento (normalizaci√≥n, codificaci√≥n binaria y divisi√≥n de datos) fue clave para mejorar el rendimiento de los modelos.

- Las m√©tricas del modelo final (accuracy: 96‚ÄØ%, sensibilidad: 94‚ÄØ%, especificidad: 98‚ÄØ%) muestran una alta capacidad para identificar correctamente tanto casos benignos como malignos.

Esto permiti√≥ seleccionar el modelo con mayor potencial diagn√≥stico en funci√≥n del dataset disponible.

## Licencia

Este proyecto est√° licenciado bajo la Licencia MIT, lo que permite su uso, modificaci√≥n y distribuci√≥n con atribuci√≥n adecuada.
</body>
